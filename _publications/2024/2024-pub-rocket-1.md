---
title:          "ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting"
date:           2025-02-27 00:01:00 +0800
selected:       true
pub:            "IEEE/CVF Computer Vision and Pattern Recognition (CVPR)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"

abstract: >-
  We propose visual-temporal context prompting, a novel communication protocol between VLMs and policy models. This protocol leverages object segmentation from past observations to guide policy-environment interactions. Using this approach, we train ROCKET-1, a low-level policy that predicts actions based on concatenated visual observations and segmentation masks, supported by real-time object tracking from SAM-2. 
cover: https://raw.githubusercontent.com/phython96/Images/master/rocket-1-logo.png
authors:
  - Shaofei Cai
  - Zihao Wang
  - Kewei Lian
  - Zhancun Mu
  - Xiaojian Ma
  - Anji Liu
  - Yitao Liang
links:
  Paper: https://huggingface.co/papers/2410.17856
  Code: https://github.com/CraftJarvis/ROCKET-1
  Demo: https://huggingface.co/spaces/phython96/ROCKET-1-DEMO
  Page: https://craftjarvis.github.io/ROCKET-1/
  Video: https://www.youtube.com/watch?v=_3Sle15iaO4
  Twitter: https://x.com/_akhaliq/status/1850905581831262543
---
