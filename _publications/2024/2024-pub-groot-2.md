---
title:          "GROOT-2: Weakly Supervised Multi-Modal Instruction Following Agents"
date:           2024-10-10 00:01:00 +0800
selected:       false
pub:            "International Conference on Learning Representations (ICLR)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge/ badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"

abstract: >-
  We frame the problem as a semi-supervised learning task and introduce GROOT-2, a multimodal instructable agent trained using a novel approach that combines weak supervision with latent variable models. Our method consists of two key components: constrained self-imitating, which utilizes large amounts of unlabeled demonstrations to enable the policy to learn diverse behaviors, and human intention alignment, which uses a smaller set of labeled demonstrations to ensure the latent space reflects human intentions. 
cover: https://raw.githubusercontent.com/phython96/Images/master/groot-2-logo.png
authors:
  - Shaofei Cai*  
  - Bowei Zhang*
  - Zihao Wang
  - Haowei Lin
  - Xiaojian Ma
  - Anji Liu
  - Yitao Liang
links:
  Paper: https://arxiv.org/abs/2412.10410
---
